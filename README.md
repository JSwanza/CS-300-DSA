# CS-300-DSA
README.md Update: CS 300 Portfolio Reflection
Project Overview
In CS 300, the projects focused on building a course planner application for the Computer Science program at ABCU. The system loads course data (course number, title, and prerequisites) from a CSV file, validates the data (format, unique courses, valid prerequisites), stores it in an efficient data structure, prints a sorted alphanumeric list of all courses, and allows users to search for a specific course to view its details and prerequisites.
What was the problem you were solving in the projects for this course?
The main problem was creating an advising tool that helps students and advisors view Computer Science course information efficiently. The data included course numbers (e.g., CSCI203), titles, and prerequisite lists, stored in a text file with potential formatting errors or invalid prerequisites. The system needed to load and validate this data, provide a sorted list of all courses for planning a schedule, and enable quick lookups of individual courses with their prerequisites displayed— all while performing well even if the course catalog grew.
How did you approach the problem? Consider why data structures are important to understand.
I approached it by progressively implementing and comparing three data structures: a vector with linear search, a hash table with chaining for fast lookups, and finally a binary search tree (BST). Starting with pseudocode milestones for each, I analyzed their trade-offs before coding the final BST version in C++.
Data structures are critical because the choice directly affects performance. A vector is simple but has O(n) search and requires separate sorting. A hash table gives O(1) average lookup but doesn't maintain order, so printing sorted requires extra work. The BST provided O(log n) search and insertion with built-in sorting via in-order traversal—perfect for both requirements without extra overhead. Understanding these options helps select the best tool for the job rather than defaulting to the simplest.
How did you overcome any roadblocks you encountered while going through the activities or project?
The biggest challenges were robust file parsing and validation (handling commas in titles was tricky, though the sample data was clean), case-insensitive user input for searches, and correctly implementing BST insertion and traversal without built-in libraries. I overcame parsing issues by using two-pass reading: first collect all course numbers for prerequisite validation, then parse fully. For search, I added uppercase conversion of input. BST bugs were fixed by careful recursive testing and adding trim/validation functions. Reading documentation, testing with small datasets, and stepping through code with print statements helped immensely.
How has your work on this project expanded your approach to designing software and developing programs?
This project reinforced analyzing requirements for key operations (load, search, sorted print) early and mapping them to Big-O complexities before coding. I now prototype multiple solutions when performance matters and consider edge cases (invalid data, duplicates, empty files) upfront. It also emphasized choosing structures that naturally support multiple needs—here, BST's ordering eliminated the need for separate sorting—leading to cleaner, more efficient designs.
How has your work on this project evolved the way you write programs that are maintainable, readable, and adaptable?
I focused more on modular code: separate functions for trim, validation, insertion, traversal, and printing. Added clear comments, consistent naming, and memory management (recursive delete for the BST). Error handling improved with meaningful messages and counters. The menu-driven interface with input validation makes it user-friendly. Overall, the progression from pseudocode to final C++ taught me to build incrementally, making the code easier to debug, extend (e.g., add more menu options), and understand later—valuable for portfolio reviews or future maintenance.
